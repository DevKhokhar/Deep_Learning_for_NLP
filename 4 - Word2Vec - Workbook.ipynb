{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install steps\n",
    "\n",
    "#### Download pip:\n",
    "- https://pip.pypa.io/en/stable/installing/\n",
    "    - To install pip, securely downloadÂ get-pip.py.\n",
    "    - python3 get-pip.py (Run in sudo or admin mode - based on the OS)\n",
    "\n",
    "#### Install Gensim Word2Vec\n",
    "- pip3 install --upgrade gensim (Run in sudo or admin mode - based on the OS)\n",
    "- pip3 install nltk\n",
    "- sudo python -m nltk.downloader -d /usr/local/share/nltk_data all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gensim and nltk:\n",
    "\n",
    "import gensim\n",
    "\n",
    "# http://www.nltk.org/book/ch02.html\n",
    "# It contains 500 samples of English-language text,\n",
    "# totaling roughly one million words, compiled from works published in the United States in 1961.\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown corpus model saved.\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "\n",
    "sentences = brown.sents()\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "model.save('brown_model')\n",
    "print(\"Brown corpus model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('father', 0.9846181869506836), ('husband', 0.9669593572616577), ('wife', 0.9486243724822998), ('friend', 0.9322052597999573), ('son', 0.9282881617546082), ('nickname', 0.9173303246498108), ('eagle', 0.9157270193099976), ('addiction', 0.906704843044281), ('voice', 0.9057698845863342), ('patient', 0.899213433265686)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Load and Test the model:\n",
    "model = gensim.models.Word2Vec.load('brown_model')\n",
    "# words most similar to mother\n",
    "print(model.most_similar('mother'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n",
      "table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# find the odd one out\n",
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
    "print(model.doesnt_match(\"cat dog table\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35715294 -0.19201484  0.06453199 -0.31812358  0.34995535  0.37117353\n",
      "  0.60374796  0.13953583  0.6168337   0.84024435 -0.4647691   0.28594983\n",
      "  0.5884796   1.4222544   1.0639894   0.36073363 -0.5001473   0.76575464\n",
      "  0.67404443  0.49063948 -0.0942038  -0.37926126  0.86331284  0.24414942\n",
      "  0.22542927  0.6314688   0.06413365 -0.3089375  -1.1719805   0.442727\n",
      " -0.06680264 -0.645871   -0.43071994 -0.87876546  0.1020586   0.06740871\n",
      "  0.51632214  0.87089676  0.12997636  0.34464735  0.00155788 -0.6318405\n",
      " -0.30814582 -0.85897815 -0.42125264 -0.22521545  0.09884993 -0.06979845\n",
      " -0.5507496  -0.48977223  1.0746925  -0.58177453  0.07736731 -0.26322338\n",
      "  0.5677904  -0.29204562  0.18040363 -1.2391508   0.36376444  0.08585867\n",
      " -0.7801938  -0.5638774  -0.09588034 -0.872432   -0.26630586  0.09761101\n",
      " -0.361726    0.15841632  0.54823333  0.46109918 -0.07567     0.69156873\n",
      "  0.68775296  0.77148163  0.6996729   1.0877684  -0.08485799  0.9228495\n",
      "  0.4553159  -0.80853957  0.74754167 -0.2104344  -0.6870117  -0.11287702\n",
      "  0.1364537  -0.45512143  0.25822312  0.5066603  -0.43509716  0.18578565\n",
      " -0.6443252   0.25416443  0.3330198   0.34549707  0.05948928 -0.4141354\n",
      " -1.3926144   0.5412137   0.00722316  0.44572237]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# vector representation of word human\n",
    "print(model[\"human\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo using pre-trained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Google News pre-trained vectors : https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase\n",
    "# Pre-trained vectors trained on part of Google News dataset (about 100 billion words). \n",
    "# The model contains 300-dimensional vectors for 3 million words and phrases.\n",
    "import gensim\n",
    "\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "# 3 million words * 300 features * 4bytes/feature = ~3.35GB\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,),\n",
       " array([ 0.10742188, -0.20117188,  0.12304688,  0.21191406, -0.09130859,\n",
       "         0.21679688, -0.13183594,  0.08300781,  0.20214844,  0.04785156],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['computer'].shape, model['computer'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spain', 0.6375303864479065),\n",
       " ('french', 0.6326056122779846),\n",
       " ('germany', 0.6314355134963989),\n",
       " ('europe', 0.626425564289093),\n",
       " ('italy', 0.6257959008216858),\n",
       " ('england', 0.6120775938034058),\n",
       " ('european', 0.6074904799461365),\n",
       " ('belgium', 0.5972345471382141),\n",
       " ('usa', 0.5948355197906494),\n",
       " ('serbia', 0.5805614590644836)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple way to investigate the learned representations is to find the closest words for a user-specified word.\n",
    "# The distance tool serves that purpose.\n",
    "model.most_similar('france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Milan', 0.7222141027450562),\n",
       " ('Rome', 0.7028310298919678),\n",
       " ('Palermo_Sicily', 0.5967569947242737),\n",
       " ('Italian', 0.5911272764205933),\n",
       " ('Tuscany', 0.563281238079071),\n",
       " ('Bologna', 0.5608358383178711),\n",
       " ('Sicily', 0.5596384406089783),\n",
       " ('Bologna_Italy', 0.5470059514045715),\n",
       " ('Berna_Milan', 0.5464027523994446),\n",
       " ('Genoa', 0.5308901071548462)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the word vectors capture many linguistic regularities, \n",
    "# for example vector operations vector('Paris') - vector('France') + vector('Italy') \n",
    "# results in a vector that is very close to vector('Rome'), \n",
    "# vector('king') - vector('man') + vector('woman') is close to vector('queen')\n",
    "model.most_similar(positive=['Paris', 'Italy'], negative=['France'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.549946129322052),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593235015869),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jal', 0.596185028553009),\n",
       " ('Nimbu', 0.5948660969734192),\n",
       " ('pura', 0.5872788429260254),\n",
       " ('saathi', 0.5830987095832825),\n",
       " ('chillum', 0.5760275721549988),\n",
       " ('paani', 0.574300229549408),\n",
       " ('pana', 0.572252094745636),\n",
       " ('mahua', 0.5707277059555054),\n",
       " ('phensidyl', 0.5696573257446289),\n",
       " ('sada', 0.5695992708206177)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('ganga')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization - Demo\n",
    "https://ronxin.github.io/wevi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
