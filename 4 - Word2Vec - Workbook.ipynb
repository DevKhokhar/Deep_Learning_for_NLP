{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install steps\n",
    "\n",
    "#### Download pip:\n",
    "- https://pip.pypa.io/en/stable/installing/\n",
    "    - To install pip, securely downloadÂ get-pip.py.\n",
    "    - python3 get-pip.py (Run in sudo or admin mode - based on the OS)\n",
    "\n",
    "#### Install Gensim Word2Vec\n",
    "- pip3 install --upgrade gensim (Run in sudo or admin mode - based on the OS)\n",
    "- pip3 install nltk\n",
    "- sudo python -m nltk.downloader -d /usr/local/share/nltk_data all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gensim and nltk:\n",
    "\n",
    "import gensim\n",
    "# http://www.nltk.org/book/ch02.html\n",
    "# It contains 500 samples of English-language text,\n",
    "# totaling roughly one million words, compiled from works published in the United States in 1961.\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown corpus model saved.\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "\n",
    "sentences = brown.sents()\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "model.save('brown_model')\n",
    "print(\"Brown corpus model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Test the model:\n",
    "model = gensim.models.Word2Vec.load('brown_model')\n",
    "# words most similar to mother\n",
    "print(model.most_similar('mother'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the odd one out\n",
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
    "print(model.doesnt_match(\"cat dog table\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector representation of word human\n",
    "print(model[\"human\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo using pre-trained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Google News pre-trained vectors : https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase\n",
    "# Pre-trained vectors trained on part of Google News dataset (about 100 billion words). \n",
    "# The model contains 300-dimensional vectors for 3 million words and phrases.\n",
    "import gensim\n",
    "\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "# 3 million words * 300 features * 4bytes/feature = ~3.35GB\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,),\n",
       " array([ 0.10742188, -0.20117188,  0.12304688,  0.21191406, -0.09130859,\n",
       "         0.21679688, -0.13183594,  0.08300781,  0.20214844,  0.04785156],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['computer'].shape, model['computer'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spain', 0.6375303864479065),\n",
       " ('french', 0.6326056122779846),\n",
       " ('germany', 0.6314355134963989),\n",
       " ('europe', 0.626425564289093),\n",
       " ('italy', 0.6257959008216858),\n",
       " ('england', 0.6120775938034058),\n",
       " ('european', 0.6074904799461365),\n",
       " ('belgium', 0.5972345471382141),\n",
       " ('usa', 0.5948355197906494),\n",
       " ('serbia', 0.5805614590644836)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple way to investigate the learned representations is to find the closest words for a user-specified word.\n",
    "# The distance tool serves that purpose.\n",
    "model.most_similar('france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Milan', 0.7222141027450562),\n",
       " ('Rome', 0.7028310298919678),\n",
       " ('Palermo_Sicily', 0.5967569947242737),\n",
       " ('Italian', 0.5911272764205933),\n",
       " ('Tuscany', 0.563281238079071),\n",
       " ('Bologna', 0.5608358383178711),\n",
       " ('Sicily', 0.5596384406089783),\n",
       " ('Bologna_Italy', 0.5470059514045715),\n",
       " ('Berna_Milan', 0.5464027523994446),\n",
       " ('Genoa', 0.5308901071548462)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the word vectors capture many linguistic regularities, \n",
    "# for example vector operations vector('Paris') - vector('France') + vector('Italy') \n",
    "# results in a vector that is very close to vector('Rome'), \n",
    "# vector('king') - vector('man') + vector('woman') is close to vector('queen')\n",
    "model.most_similar(positive=['Paris', 'Italy'], negative=['France'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.549946129322052),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593235015869),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jal', 0.596185028553009),\n",
       " ('Nimbu', 0.5948660969734192),\n",
       " ('pura', 0.5872788429260254),\n",
       " ('saathi', 0.5830987095832825),\n",
       " ('chillum', 0.5760275721549988),\n",
       " ('paani', 0.574300229549408),\n",
       " ('pana', 0.572252094745636),\n",
       " ('mahua', 0.5707277059555054),\n",
       " ('phensidyl', 0.5696573257446289),\n",
       " ('sada', 0.5695992708206177)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('ganga')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization - Demo\n",
    "https://ronxin.github.io/wevi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
